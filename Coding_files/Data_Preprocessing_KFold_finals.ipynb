{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "DIR = \"data_sets/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "MZMRW7nfswRu"
   },
   "outputs": [],
   "source": [
    "# importing panda library\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from openpyxl import load_workbook\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from files.measures import n_1_imb_mean, n_3_imb_mean, tlcm, degOver, degIR, imbalance_ratio\n",
    "import numpy as np \n",
    "from sklearn.utils import Bunch\n",
    "import pandas as pd \n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import os\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['.ipynb_checkpoints',\n",
       " 'australian.csv',\n",
       " 'balance.csv',\n",
       " 'bands.csv',\n",
       " 'banknoteauthentication.csv',\n",
       " 'bloodtransfusion.csv',\n",
       " 'bupa.csv',\n",
       " 'car_eval_34.csv',\n",
       " 'car_eval_4.csv',\n",
       " 'cleveland-0_vs_4.csv']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_list = os.listdir(DIR)\n",
    "len(file_list)\n",
    "file_list[0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def unique(list1):\n",
    " \n",
    "    # initialize a null list\n",
    "    unique_list = []\n",
    " \n",
    "    # traverse for all elements\n",
    "    for x in list1:\n",
    "        # check if exists in unique_list or not\n",
    "        if x not in unique_list:\n",
    "            unique_list.append(x)\n",
    "    # print list\n",
    "    for x in unique_list:\n",
    "        print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "names = []\n",
    "filename = []\n",
    "error_files = []\n",
    "good_files = []\n",
    "\n",
    "for i in range(len(file_list)):\n",
    "    if file_list[i] == \".ipynb_checkpoints\":\n",
    "        pass\n",
    "    else:\n",
    "        df = pd.read_csv(f\"{DIR}/{file_list[i]}\")\n",
    "        names.append(df.columns[-1])\n",
    "        filename.append(file_list[i])\n",
    "\n",
    "for i in range(len(names)):\n",
    "    if names[i] in [\"Output\", \"Output\", \"outcome\", \"output\"]:\n",
    "        good_files.append(filename[i])\n",
    "    else:\n",
    "        error_files.append(filename[i])     \n",
    "        \n",
    "error_files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(dataset) -> Bunch: \n",
    "    dataset=np.array(dataset)\n",
    "    X = dataset[:,0:-1]\n",
    "    y = dataset[:,-1]\n",
    "    return Bunch(data=np.array(X), target=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def result_df(dataset_): \n",
    "    n_1_score = n_1_imb_mean(dataset_) \n",
    "    n_3_score = n_3_imb_mean(dataset_)\n",
    "    tlcm_score = tlcm(dataset_)   \n",
    "    degOver_score = degOver(dataset_)\n",
    "    degIR_score = degIR(dataset_)\n",
    "    ir_score = imbalance_ratio(dataset_)\n",
    "    return  n_1_score, n_3_score,tlcm_score, degOver_score, degIR_score, ir_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def excel_manipulator(filename):\n",
    "    new_df = pd.read_csv(f\"final_result_{filename}.csv\")\n",
    "    new_df.to_excel(f\"final_result_{filename}.xlsx\")\n",
    "    new_df = pd.read_excel(f\"final_result_{filename}.xlsx\")\n",
    "    new_df = new_df.drop(new_df.columns[0], axis=1)\n",
    "    new_df.to_excel(f\"final_result_{filename}_excel.xlsx\")\n",
    "    workbook = load_workbook(filename=f\"final_result_{filename}_excel.xlsx\")\n",
    "    sheet = workbook.active\n",
    "    sheet[\"B1\"].value = f\"{filename}\"\n",
    "    workbook.save(f'{filename}_modified.xlsx')\n",
    "    df = pd.read_excel(f'{filename}_modified.xlsx')\n",
    "    df = df.drop(df.columns[0], axis=1)\n",
    "    df.to_excel(\"{filename}_modified.xlsx\", index = False)\n",
    "    os.remove(f\"final_result_{filename}_excel.xlsx\")\n",
    "    os.remove(f\"final_result_{filename}.xlsx\")\n",
    "    os.remove(f\"final_result_{filename}.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 206
    },
    "id": "gmnhdRBSlSxk",
    "outputId": "1a2435c8-15e1-42d0-8aa8-3a2d6f089596"
   },
   "outputs": [],
   "source": [
    "def process(filename):\n",
    "    dataframe=pd.read_csv(f\"{DIR}/{filename}\")\n",
    "    \n",
    "    column_name = dataframe.columns[-1]\n",
    "    y=dataframe[f'{column_name}']\n",
    "    X=dataframe.drop([f'{column_name}'], axis=1)\n",
    "    complexity_measure_train={}\n",
    "    complexity_measure_test={}\n",
    "    skf = StratifiedKFold(n_splits=5, random_state=55, shuffle=True)\n",
    "    \n",
    "    \n",
    "    for i, (train_index, test_index) in enumerate(skf.split(dataframe, y)):\n",
    "      train_=dataframe.loc[train_index,:]\n",
    "      with open(f\"{filename}_train_indices.txt\", \"w\") as output:\n",
    "        for j in range(5):\n",
    "           output.write(str(train_index))\n",
    "\n",
    "      dataset_train=load_dataset(train_)\n",
    "      complexity_measure_train[\"train_\"+ str(i)]={}\n",
    "      n_1_score, n_3_score,tlcm_score,degOver_score, degIR_score, ir_score=result_df(dataset_train)\n",
    "      complexity_measure_train[\"train_\"+ str(i)][\"n_1_score\"]=n_1_score\n",
    "      complexity_measure_train[\"train_\"+ str(i)][\"n_3_score\"]=n_3_score\n",
    "      complexity_measure_train[\"train_\"+ str(i)][\"tlcm_score\"]=tlcm_score\n",
    "      complexity_measure_train[\"train_\"+ str(i)][\"degOver_score\"]=degOver_score\n",
    "      complexity_measure_train[\"train_\"+ str(i)][\"degIR_score\"]=degIR_score\n",
    "      complexity_measure_train[\"train_\"+ str(i)][\"IR_score\"]=ir_score\n",
    "\n",
    "      test_= dataframe.loc[test_index,:]\n",
    "      with open(f\"{filename}_test_indices.txt\", \"w\") as output:\n",
    "        for j in range(5):\n",
    "          output.write(str(test_index))\n",
    "\n",
    "      dataset_test=load_dataset(test_)\n",
    "      complexity_measure_test[\"test_\"+ str(i)]={}\n",
    "      n_1_score, n_3_score,tlcm_score,degOver_score, degIR_score, ir_score=result_df(dataset_test)\n",
    "      complexity_measure_test[\"test_\"+ str(i)][\"n_1_score\"]=n_1_score\n",
    "      complexity_measure_test[\"test_\"+ str(i)][\"n_3_score\"]=n_3_score\n",
    "      complexity_measure_test[\"test_\"+ str(i)][\"tlcm_score\"]=tlcm_score\n",
    "      complexity_measure_test[\"test_\"+ str(i)][\"degOver_score\"]=degOver_score\n",
    "      complexity_measure_test[\"test_\"+ str(i)][\"degIR_score\"]=degIR_score\n",
    "      complexity_measure_test[\"test_\"+ str(i)][\"IR_score\"]=ir_score\n",
    "      i+=1\n",
    "    \n",
    "    df_train_set= pd.DataFrame.from_dict(complexity_measure_train)  \n",
    "    df_train_set.transpose()\n",
    "    \n",
    "    plt.figure(figsize=(7,5))\n",
    "    sns.boxplot(data=df_train_set.transpose(), whis=[0, 100], width=.6, palette=\"vlag\")\n",
    "    sns.stripplot(data=df_train_set.transpose(),size=4,color=\".3\", linewidth=0)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    df_test_set= pd.DataFrame.from_dict(complexity_measure_test)\n",
    "\n",
    "    plt.figure(figsize=(8,5))\n",
    "    sns.boxplot(data=df_test_set.transpose(), whis=[0, 100], width=.6, palette=\"vlag\")\n",
    "    sns.stripplot(data=df_test_set.transpose(),size=4,color=\".3\", linewidth=0)\n",
    "    plt.xticks(rotation=45)\n",
    "    plt.tight_layout()\n",
    "    \n",
    "    result= df_train_set.transpose().mean()\n",
    "    final_result= pd.DataFrame(result, columns=[\"Train_Mean_Score\"])\n",
    "    final_result[\"Train_standard_deviation\"]=df_train_set.transpose().std()\n",
    "    final_result[\"Test_Mean_Score\"]=df_test_set.transpose().mean()\n",
    "    final_result[\"Test_standard_deviation\"]=df_test_set.transpose().std()\n",
    "    \n",
    "    final_result.transpose().to_csv(f\"final_result_{filename}\")\n",
    "    \n",
    "    final_result.drop(['IR_score'], inplace=True)\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(final_result.index, final_result[\"Train_Mean_Score\"], yerr=final_result['Train_standard_deviation'], align='center', alpha=0.8, ecolor='black', capsize=12)\n",
    "    ax.set_xticks(final_result.index)\n",
    "    ax.set_ylabel('Range')\n",
    "    ax.set_title(f'{filename.replace(\".csv\",\"\")}')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{filename.replace(\".csv\",\"\")}_Train_bar_plot_with_error_bars.png')\n",
    "\n",
    "    \n",
    "    fig, ax = plt.subplots()\n",
    "    ax.bar(final_result.index, final_result[\"Test_Mean_Score\"], yerr=final_result['Test_standard_deviation'], align='center', alpha=0.8, ecolor='black', capsize=12)\n",
    "    ax.set_xticks(final_result.index)\n",
    "    ax.set_title(f'{filename.replace(\".csv\",\"\")}')\n",
    "    ax.set_ylabel('Range')\n",
    "    ax.yaxis.grid(True)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f'{filename.replace(\".csv\",\"\")}_Test_bar_plot_with_error_bars.png')\n",
    "    \n",
    "    \n",
    "    filename = filename[:-4]\n",
    "    excel_manipulator(filename)\n",
    "\n",
    "        \n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  2%|‚ñè         | 3/143 [01:03<53:36, 22.97s/it]"
     ]
    }
   ],
   "source": [
    "for i in tqdm(range(len(good_files))):\n",
    "     if file_list[i] not in ('.ipynb_checkpoints'):\n",
    "            process(file_list[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
