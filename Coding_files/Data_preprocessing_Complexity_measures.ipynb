{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: modin in c:\\users\\amind\\anaconda3\\lib\\site-packages (0.19.0)\n",
      "Requirement already satisfied: numpy>=1.18.5 in c:\\users\\amind\\anaconda3\\lib\\site-packages (from modin) (1.23.5)\n",
      "Requirement already satisfied: psutil in c:\\users\\amind\\anaconda3\\lib\\site-packages (from modin) (5.9.0)\n",
      "Requirement already satisfied: fsspec in c:\\users\\amind\\anaconda3\\lib\\site-packages (from modin) (2022.11.0)\n",
      "Requirement already satisfied: packaging in c:\\users\\amind\\anaconda3\\lib\\site-packages (from modin) (22.0)\n",
      "Requirement already satisfied: pandas==1.5.3 in c:\\users\\amind\\anaconda3\\lib\\site-packages (from modin) (1.5.3)\n",
      "Requirement already satisfied: python-dateutil>=2.8.1 in c:\\users\\amind\\anaconda3\\lib\\site-packages (from pandas==1.5.3->modin) (2.8.2)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\amind\\anaconda3\\lib\\site-packages (from pandas==1.5.3->modin) (2022.7)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\amind\\anaconda3\\lib\\site-packages (from python-dateutil>=2.8.1->pandas==1.5.3->modin) (1.16.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "ResourceWarning: unclosed file <_io.BufferedReader name=5>\n",
      "ResourceWarning: unclosed socket <zmq.Socket(zmq.PUSH) at 0x1b6439eef20>\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: interruptingcow in c:\\users\\amind\\anaconda3\\lib\\site-packages (0.8)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ResourceWarning: unclosed file <_io.BufferedWriter name=3>\n",
      "ResourceWarning: unclosed file <_io.BufferedReader name=4>\n",
      "ResourceWarning: unclosed file <_io.BufferedReader name=5>\n"
     ]
    }
   ],
   "source": [
    "!pip install modin\n",
    "!pip install interruptingcow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "Xj4_Y1OGgx0j"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from files.measures import n_1_imb_mean, n_3_imb_mean, tlcm, degOver, degIR, imbalance_ratio\n",
    "import numpy as np \n",
    "from sklearn.utils import Bunch\n",
    "import modin.pandas as pd \n",
    "from tqdm import tqdm\n",
    "from interruptingcow import timeout\n",
    "import os\n",
    "os.cpu_count()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "pqXkShYajXdY"
   },
   "outputs": [],
   "source": [
    "def load_dataset(path_: str) -> Bunch: \n",
    "    dataset = np.genfromtxt(path_, skip_header=True, delimiter=\",\")\n",
    "    X = dataset[:,0:-1]\n",
    "    y = dataset[:,-1]\n",
    "    return Bunch(data=np.array(X), target=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ueetdQU1jcvA"
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 15\u001b[0m\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m dataset \u001b[38;5;129;01min\u001b[39;00m datasets:\n\u001b[0;32m     14\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m dataset \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m (\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m.ipynb_checkpoints\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[1;32m---> 15\u001b[0m      dataset_\u001b[38;5;241m=\u001b[39m\u001b[43mload_dataset\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     16\u001b[0m      processed_dataset\u001b[38;5;241m.\u001b[39mappend(dataset_)\n\u001b[0;32m     17\u001b[0m      dataset_name\u001b[38;5;241m.\u001b[39mappend(dataset)\n",
      "Cell \u001b[1;32mIn[17], line 2\u001b[0m, in \u001b[0;36mload_dataset\u001b[1;34m(path_)\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mload_dataset\u001b[39m(path_: \u001b[38;5;28mstr\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Bunch: \n\u001b[1;32m----> 2\u001b[0m     dataset \u001b[38;5;241m=\u001b[39m \u001b[43mnp\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenfromtxt\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpath_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mskip_header\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdelimiter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m,\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m      3\u001b[0m     X \u001b[38;5;241m=\u001b[39m dataset[:,\u001b[38;5;241m0\u001b[39m:\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n\u001b[0;32m      4\u001b[0m     y \u001b[38;5;241m=\u001b[39m dataset[:,\u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m]\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:2306\u001b[0m, in \u001b[0;36mgenfromtxt\u001b[1;34m(fname, dtype, comments, delimiter, skip_header, skip_footer, converters, missing_values, filling_values, usecols, names, excludelist, deletechars, replace_space, autostrip, case_sensitive, defaultfmt, unpack, usemask, loose, invalid_raise, max_rows, encoding, ndmin, like)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;66;03m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;66;03m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loose:\n\u001b[0;32m   2305\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m-> 2306\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[[conv\u001b[38;5;241m.\u001b[39m_loose_call(_r) \u001b[38;5;28;01mfor\u001b[39;00m _r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2307\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m (i, conv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2309\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[[conv\u001b[38;5;241m.\u001b[39m_strict_call(_r) \u001b[38;5;28;01mfor\u001b[39;00m _r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2311\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m (i, conv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:2306\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;66;03m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;66;03m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loose:\n\u001b[0;32m   2305\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m-> 2306\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[[conv\u001b[38;5;241m.\u001b[39m_loose_call(_r) \u001b[38;5;28;01mfor\u001b[39;00m _r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2307\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m (i, conv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2309\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[[conv\u001b[38;5;241m.\u001b[39m_strict_call(_r) \u001b[38;5;28;01mfor\u001b[39;00m _r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2311\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m (i, conv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(converters)]))\n",
      "File \u001b[1;32m~\\anaconda3\\lib\\site-packages\\numpy\\lib\\npyio.py:2306\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m   2302\u001b[0m \u001b[38;5;66;03m# Convert each value according to the converter:\u001b[39;00m\n\u001b[0;32m   2303\u001b[0m \u001b[38;5;66;03m# We want to modify the list in place to avoid creating a new one...\u001b[39;00m\n\u001b[0;32m   2304\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loose:\n\u001b[0;32m   2305\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[1;32m-> 2306\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[[conv\u001b[38;5;241m.\u001b[39m_loose_call(_r) \u001b[38;5;28;01mfor\u001b[39;00m _r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2307\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m (i, conv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(converters)]))\n\u001b[0;32m   2308\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   2309\u001b[0m     rows \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mlist\u001b[39m(\n\u001b[0;32m   2310\u001b[0m         \u001b[38;5;28mzip\u001b[39m(\u001b[38;5;241m*\u001b[39m[[conv\u001b[38;5;241m.\u001b[39m_strict_call(_r) \u001b[38;5;28;01mfor\u001b[39;00m _r \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mmap\u001b[39m(itemgetter(i), rows)]\n\u001b[0;32m   2311\u001b[0m               \u001b[38;5;28;01mfor\u001b[39;00m (i, conv) \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(converters)]))\n",
      "\u001b[1;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    " # example with ecoli3 and pima works, because of the way they are formatted \n",
    "# When everything is formatted we can loop over all of the files in the data dir. \n",
    "processed_dataset=[]\n",
    "dataset_name=[]\n",
    "filepath=\"data_sets/\"\n",
    "\n",
    "import os\n",
    "datasets = []\n",
    "\n",
    "datasets = os.listdir(\"data_sets/\")\n",
    "\n",
    "\n",
    "for dataset in datasets:\n",
    "     if dataset not in ('.ipynb_checkpoints'):\n",
    "      dataset_=load_dataset(filepath + dataset)\n",
    "      processed_dataset.append(dataset_)\n",
    "      dataset_name.append(dataset)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YpyR7IfaZM-m"
   },
   "outputs": [],
   "source": [
    "len(processed_dataset), len(dataset_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ppNZ_wCZFH6H"
   },
   "outputs": [],
   "source": [
    "new_list=[]\n",
    "for i in range(len(processed_dataset)):\n",
    "  new_list.append([dataset_name[i], processed_dataset[i]])\n",
    "\n",
    "new_list[75]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Baw8uMewx0tJ"
   },
   "outputs": [],
   "source": [
    "len(new_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YjWkPu1RXL8I"
   },
   "outputs": [],
   "source": [
    "for i in range(len(processed_dataset)):\n",
    "  print(new_list[i][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BQMzMK6xjx-0"
   },
   "outputs": [],
   "source": [
    "# Instead of the following print, we could change the function to take an array of datasets, and then output a dataframe, containing the measures\n",
    "# for all of the datasets. This could be each row represents a dataset, so column 1 of the dataset is equal to dataset_name and the rest of the columns is equal\n",
    "# to the results of the measures.  \n",
    "\"\"\" \n",
    "[ dataset,N1, N3, TLCM,... ]\n",
    "[ abalone ,0.35, 0.20, 0.40,... ]\n",
    "[ abalone2 ,0.35, 0.20, 0.40,... ]\n",
    "[ ..., ..., ..., ... ,...]\n",
    "\n",
    "\"\"\"\n",
    "def result_df(dataset_): \n",
    "    n_1_score = n_1_imb_mean(dataset_) \n",
    "    n_3_score = n_3_imb_mean(dataset_)\n",
    "    tlcm_score = tlcm(dataset_)   \n",
    "    degOver_score = degOver(dataset_)\n",
    "    degIR_score = degIR(dataset_)\n",
    "    ir_score = imbalance_ratio(dataset_)\n",
    "    return  n_1_score, n_3_score,tlcm_score, degOver_score, degIR_score, ir_score\n",
    "\n",
    "    #print(f\"N1 score: {n_1_score}\\nN3 score: {n_3_score}\\nTLCM score: {tlcm_score}\\ndegOver: {degOver_score}\\ndegIR: {degIR_score}\\nIR: {ir_score}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6pBbDvXvbblC"
   },
   "outputs": [],
   "source": [
    "complexity_measure={}\n",
    "\n",
    "    \n",
    "for i in tqdm(range(len(processed_dataset))):\n",
    "      dataset_name=new_list[i][0]\n",
    "      dataset_name=dataset_name.replace(\".csv\",\"\")\n",
    "      print(f\"Current Dataset: {dataset_name}\")\n",
    "      dataset_=new_list[i][1]\n",
    "      complexity_measure[dataset_name]={}\n",
    "      n_1_score, n_3_score,tlcm_score,degOver_score, degIR_score, ir_score=result_df(dataset_)\n",
    "      complexity_measure[dataset_name][\"n_1_score\"]=n_1_score\n",
    "      complexity_measure[dataset_name][\"n_3_score\"]=n_3_score\n",
    "      complexity_measure[dataset_name][\"tlcm_score\"]=tlcm_score\n",
    "      complexity_measure[dataset_name][\"degOver_score\"]=degOver_score\n",
    "      complexity_measure[dataset_name][\"degIR_score\"]=degIR_score\n",
    "      complexity_measure[dataset_name][\"Ir_score\"]=ir_score\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "VcWVKcOBY7X2"
   },
   "outputs": [],
   "source": [
    "complexity_measure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "JGlEoElKiT0x"
   },
   "outputs": [],
   "source": [
    "df= pd.DataFrame.from_dict(complexity_measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "59zAvRfZia1o"
   },
   "outputs": [],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BzeZZK51k4Hq"
   },
   "outputs": [],
   "source": [
    "dataframe =df.transpose()\n",
    "dataframe.to_csv(\"final_results.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oG-gtcEtgDsu"
   },
   "outputs": [],
   "source": [
    "dataframe.sort_values(by=['n_1_score', 'n_3_score','tlcm_score'], inplace=True,  ascending=True)\n",
    "dataframe.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YOvHEY8llw4v"
   },
   "outputs": [],
   "source": [
    "# Plot and compare all of the model results\n",
    "import matplotlib.pyplot as plt\n",
    "dataframe.drop(['Ir_score','degIR_score'],axis=1).plot(kind=\"bar\",stacked=True, figsize=(9,6)).legend(bbox_to_anchor=(1.0, 1.0),title=\"Complexity_Score\");\n",
    "# Saving the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_bar.jpg\", dpi=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1_J40L_luIKu"
   },
   "outputs": [],
   "source": [
    "# Plot and compare all of the model results\n",
    "dataframe.drop(['Ir_score','degIR_score'],axis=1).plot(kind=\"barh\",stacked=True, figsize=(8,8)).legend(bbox_to_anchor=(1.0, 1.0), title=\"Complexity_Score\");\n",
    "# Saving the figure\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"output_barh.jpg\",dpi=100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "oZ4ov9nKicdO"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "plt.figure(figsize=(9,6))\n",
    "sns_plot=sns.lineplot(data=dataframe).legend(bbox_to_anchor=(1.0, 1.0), title=\"Complexity_Score\")\n",
    "plt.xticks(rotation=90)\n",
    "plt.show()\n",
    "fig=sns_plot.get_figure()\n",
    "plt.tight_layout()"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "machine_shape": "hm",
   "private_outputs": true,
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
