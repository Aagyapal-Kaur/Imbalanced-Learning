{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install modin\n",
        "!pip install interruptingcow"
      ],
      "metadata": {
        "id": "UtRqyYjtsrYT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xj4_Y1OGgx0j"
      },
      "outputs": [],
      "source": [
        "from files.measures import n_1_imb_mean, n_3_imb_mean, tlcm, degOver, degIR, imbalance_ratio\n",
        "import numpy as np \n",
        "from sklearn.utils import Bunch\n",
        "import modin.pandas as pd \n",
        "from tqdm import tqdm\n",
        "from interruptingcow import timeout\n",
        "import os\n",
        "os.cpu_count()\n",
        "import numpy as np \n",
        "from sklearn.utils import Bunch\n",
        "import modin.pandas as pd \n",
        "from tqdm import tqdm\n",
        "from interruptingcow import timeout\n",
        "import os\n",
        "os.cpu_count()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pqXkShYajXdY"
      },
      "outputs": [],
      "source": [
        "def load_dataset(path_: str) -> Bunch: \n",
        "    dataset = np.genfromtxt(path_, skip_header=True, delimiter=\",\")\n",
        "    X = dataset[:,0:-1]\n",
        "    y = dataset[:,-1]\n",
        "    return Bunch(data=np.array(X), target=y)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ueetdQU1jcvA"
      },
      "outputs": [],
      "source": [
        " # example with ecoli3 and pima works, because of the way they are formatted \n",
        "# When everything is formatted we can loop over all of the files in the data dir. \n",
        "processed_dataset=[]\n",
        "dataset_name=[]\n",
        "filepath=\"data_files/\"\n",
        "\n",
        "import os\n",
        "datasets = []\n",
        "\n",
        "datasets = os.listdir(\"data_files/\")\n",
        "\n",
        "\n",
        "for dataset in datasets:\n",
        "    if dataset != \".DS_Store\":\n",
        "      dataset_=load_dataset(filepath + dataset)\n",
        "      processed_dataset.append(dataset_)\n",
        "      dataset_name.append(dataset)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YpyR7IfaZM-m"
      },
      "outputs": [],
      "source": [
        "len(processed_dataset), len(dataset_name)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ppNZ_wCZFH6H"
      },
      "outputs": [],
      "source": [
        "new_list=[]\n",
        "for i in range(len(processed_dataset)):\n",
        "  new_list.append([dataset_name[i], processed_dataset[i]])\n",
        "\n",
        "new_list[75]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Baw8uMewx0tJ"
      },
      "outputs": [],
      "source": [
        "len(new_list)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YjWkPu1RXL8I"
      },
      "outputs": [],
      "source": [
        "for i in range(len(processed_dataset)):\n",
        "  print(new_list[i][0])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BQMzMK6xjx-0"
      },
      "outputs": [],
      "source": [
        "# Instead of the following print, we could change the function to take an array of datasets, and then output a dataframe, containing the measures\n",
        "# for all of the datasets. This could be each row represents a dataset, so column 1 of the dataset is equal to dataset_name and the rest of the columns is equal\n",
        "# to the results of the measures.  \n",
        "\"\"\" \n",
        "[ dataset,N1, N3, TLCM,... ]\n",
        "[ abalone ,0.35, 0.20, 0.40,... ]\n",
        "[ abalone2 ,0.35, 0.20, 0.40,... ]\n",
        "[ ..., ..., ..., ... ,...]\n",
        "\n",
        "\"\"\"\n",
        "def result_df(dataset_): \n",
        "    n_1_score = n_1_imb_mean(dataset_) \n",
        "    n_3_score = n_3_imb_mean(dataset_)\n",
        "    tlcm_score = tlcm(dataset_)   \n",
        "    degOver_score = degOver(dataset_)\n",
        "    degIR_score = degIR(dataset_)\n",
        "    ir_score = imbalance_ratio(dataset_)\n",
        "    return  n_1_score, n_3_score,tlcm_score, degOver_score, degIR_score, ir_score\n",
        "\n",
        "    #print(f\"N1 score: {n_1_score}\\nN3 score: {n_3_score}\\nTLCM score: {tlcm_score}\\ndegOver: {degOver_score}\\ndegIR: {degIR_score}\\nIR: {ir_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6pBbDvXvbblC"
      },
      "outputs": [],
      "source": [
        "complexity_measure={}\n",
        "\n",
        "    \n",
        "for i in tqdm(range(len(processed_dataset))):\n",
        "      dataset_name=new_list[i][0]\n",
        "      dataset_name=dataset_name.replace(\".csv\",\"\")\n",
        "      print(f\"Current Dataset: {dataset_name}\")\n",
        "      dataset_=new_list[i][1]\n",
        "      complexity_measure[dataset_name]={}\n",
        "      n_1_score, n_3_score,tlcm_score,degOver_score, degIR_score, ir_score=result_df(dataset_)\n",
        "      complexity_measure[dataset_name][\"n_1_score\"]=n_1_score\n",
        "      complexity_measure[dataset_name][\"n_3_score\"]=n_3_score\n",
        "      complexity_measure[dataset_name][\"tlcm_score\"]=tlcm_score\n",
        "      complexity_measure[dataset_name][\"degOver_score\"]=degOver_score\n",
        "      complexity_measure[dataset_name][\"degIR_score\"]=degIR_score\n",
        "      complexity_measure[dataset_name][\"Ir_score\"]=ir_score\n",
        " "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcWVKcOBY7X2"
      },
      "outputs": [],
      "source": [
        "complexity_measure"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JGlEoElKiT0x"
      },
      "outputs": [],
      "source": [
        "df= pd.DataFrame.from_dict(complexity_measure)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "59zAvRfZia1o"
      },
      "outputs": [],
      "source": [
        "df.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BzeZZK51k4Hq"
      },
      "outputs": [],
      "source": [
        "dataframe =df.transpose()\n",
        "dataframe.to_csv(\"final_results.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oG-gtcEtgDsu"
      },
      "outputs": [],
      "source": [
        "dataframe.sort_values(by=['n_1_score', 'n_3_score','tlcm_score'], inplace=True,  ascending=True)\n",
        "dataframe.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "YOvHEY8llw4v"
      },
      "outputs": [],
      "source": [
        "# Plot and compare all of the model results\n",
        "import matplotlib.pyplot as plt\n",
        "dataframe.drop(['Ir_score', 'degIR_score'],axis=1).plot(kind=\"bar\",stacked=True, figsize=(9,6)).legend(bbox_to_anchor=(1.0, 1.0),title=\"Complexity_Score\");\n",
        "# Saving the figure\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"output_bar.jpg\", dpi=100)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1_J40L_luIKu"
      },
      "outputs": [],
      "source": [
        "# Plot and compare all of the model results\n",
        "dataframe.drop(['Ir_score', 'degIR_score'],axis=1).plot(kind=\"barh\",stacked=True, figsize=(8,8)).legend(bbox_to_anchor=(1.0, 1.0), title=\"Complexity_Score\");\n",
        "# Saving the figure\n",
        "plt.tight_layout()\n",
        "plt.savefig(\"output_barh.jpg\",dpi=100)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "oZ4ov9nKicdO"
      },
      "outputs": [],
      "source": [
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "plt.figure(figsize=(9,6))\n",
        "sns_plot=sns.lineplot(data=dataframe).legend(bbox_to_anchor=(1.0, 1.0), title=\"Complexity_Score\")\n",
        "plt.xticks(rotation=90)\n",
        "plt.show()\n",
        "fig=sns_plot.get_figure()\n",
        "plt.tight_layout()"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}